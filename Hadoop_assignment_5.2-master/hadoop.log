2017-05-02 06:39:17,792 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 06:39:18,186 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 06:39:51,565 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 06:39:51,850 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 06:39:52,389 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 06:39:52,392 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 06:39:52,478 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 06:39:52,583 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 06:39:53,001 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local522853550_0001
2017-05-02 06:39:53,344 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 06:39:53,345 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local522853550_0001
2017-05-02 06:39:53,356 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 06:39:53,375 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 06:39:53,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 06:39:53,469 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local522853550_0001_m_000000_0
2017-05-02 06:39:53,679 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 06:39:53,690 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Assignment1_1/television.txt:0+716
2017-05-02 06:39:53,779 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 06:39:53,780 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 06:39:53,780 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 06:39:53,780 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 06:39:53,784 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 06:39:53,790 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-05-02 06:39:53,826 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-05-02 06:39:53,826 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 06:39:53,827 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 06:39:53,827 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 06:39:53,827 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 06:39:53,837 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 06:39:53,837 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 26214324(104857296)
2017-05-02 06:39:53,838 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 06:39:53,838 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 06:39:53,838 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 06:39:53,839 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@463bb934
java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:87)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2012)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:794)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 16 more
2017-05-02 06:39:53,846 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 06:39:53,847 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local522853550_0001
java.lang.Exception: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:87)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:790)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 15 more
2017-05-02 06:39:54,351 INFO org.apache.hadoop.mapreduce.Job: Job job_local522853550_0001 running in uber mode : false
2017-05-02 06:39:54,376 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-05-02 06:39:54,378 INFO org.apache.hadoop.mapreduce.Job: Job job_local522853550_0001 failed with state FAILED due to: NA
2017-05-02 06:39:54,395 INFO org.apache.hadoop.mapreduce.Job: Counters: 10
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=540
		Map output materialized bytes=0
		Input split bytes=141
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
	File Input Format Counters 
		Bytes Read=716
2017-05-02 11:17:51,656 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 11:17:52,047 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 11:17:52,430 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 11:17:52,439 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 11:17:52,486 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 11:17:52,613 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 11:17:52,817 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local797048055_0001
2017-05-02 11:17:53,118 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 11:17:53,119 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local797048055_0001
2017-05-02 11:17:53,121 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 11:17:53,138 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 11:17:53,205 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 11:17:53,209 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local797048055_0001_m_000000_0
2017-05-02 11:17:53,281 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 11:17:53,295 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Task10/Task10:0+187
2017-05-02 11:17:53,518 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 11:17:53,526 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 11:17:53,526 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 11:17:53,526 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 11:17:53,526 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 11:17:53,539 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-05-02 11:17:53,575 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-05-02 11:17:53,581 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 11:17:53,581 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 11:17:53,584 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 347; bufvoid = 104857600
2017-05-02 11:17:53,585 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600
2017-05-02 11:17:53,635 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-05-02 11:17:53,677 INFO org.apache.hadoop.mapred.Task: Task:attempt_local797048055_0001_m_000000_0 is done. And is in the process of committing
2017-05-02 11:17:53,714 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-05-02 11:17:53,715 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local797048055_0001_m_000000_0' done.
2017-05-02 11:17:53,715 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local797048055_0001_m_000000_0
2017-05-02 11:17:53,716 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 11:17:53,726 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-05-02 11:17:53,730 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local797048055_0001_r_000000_0
2017-05-02 11:17:53,777 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 11:17:53,791 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14e3ae02
2017-05-02 11:17:53,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 11:17:53,880 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local797048055_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 11:17:53,993 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local797048055_0001_m_000000_0 decomp: 429 len: 433 to MEMORY
2017-05-02 11:17:54,020 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 429 bytes from map-output for attempt_local797048055_0001_m_000000_0
2017-05-02 11:17:54,144 INFO org.apache.hadoop.mapreduce.Job: Job job_local797048055_0001 running in uber mode : false
2017-05-02 11:17:54,151 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-05-02 11:17:54,227 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 429, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->429
2017-05-02 11:17:54,238 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 11:17:54,239 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 11:17:54,241 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 11:17:54,264 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 11:17:54,267 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 425 bytes
2017-05-02 11:17:54,271 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 429 bytes to disk to satisfy reduce memory limit
2017-05-02 11:17:54,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 433 bytes from disk
2017-05-02 11:17:54,277 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 11:17:54,278 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 11:17:54,279 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 425 bytes
2017-05-02 11:17:54,285 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 11:17:54,336 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-05-02 11:17:54,359 INFO org.apache.hadoop.mapred.Task: Task:attempt_local797048055_0001_r_000000_0 is done. And is in the process of committing
2017-05-02 11:17:54,366 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 11:17:54,367 INFO org.apache.hadoop.mapred.Task: Task attempt_local797048055_0001_r_000000_0 is allowed to commit now
2017-05-02 11:17:54,374 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local797048055_0001_r_000000_0' to file:/home/acadgild/workspace/Assignments/Output/Task10/_temporary/0/task_local797048055_0001_r_000000
2017-05-02 11:17:54,378 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 11:17:54,378 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local797048055_0001_r_000000_0' done.
2017-05-02 11:17:54,378 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local797048055_0001_r_000000_0
2017-05-02 11:17:54,381 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-05-02 11:17:55,172 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-05-02 11:17:55,172 INFO org.apache.hadoop.mapreduce.Job: Job job_local797048055_0001 completed successfully
2017-05-02 11:17:55,199 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1634
		FILE: Number of bytes written=379167
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=40
		Map output bytes=347
		Map output materialized bytes=433
		Input split bytes=126
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=433
		Reduce input records=40
		Reduce output records=26
		Spilled Records=80
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=61
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=270671872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=187
	File Output Format Counters 
		Bytes Written=542
2017-05-02 17:13:45,638 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:13:46,567 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:14:00,226 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:14:00,628 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:14:01,110 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 17:14:01,113 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 17:14:01,172 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 17:14:01,318 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 17:14:01,562 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1897020509_0001
2017-05-02 17:14:01,944 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 17:14:01,947 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1897020509_0001
2017-05-02 17:14:01,945 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 17:14:01,967 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 17:14:02,036 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 17:14:02,037 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1897020509_0001_m_000000_0
2017-05-02 17:14:02,116 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 17:14:02,124 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Assignment1_1/television.txt:0+716
2017-05-02 17:14:02,219 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 17:14:02,220 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 17:14:02,221 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 17:14:02,221 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 17:14:02,221 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 17:14:02,221 WARN org.apache.hadoop.mapred.MapTask: Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.ClassCastException: class Assignment5_2.CompanyProduct
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:887)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1001)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:401)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:695)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:767)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-05-02 17:14:02,226 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 17:14:02,227 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1897020509_0001
java.lang.Exception: java.io.IOException: Unable to initialize any output collector
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Unable to initialize any output collector
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:412)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:695)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:767)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-05-02 17:14:02,959 INFO org.apache.hadoop.mapreduce.Job: Job job_local1897020509_0001 running in uber mode : false
2017-05-02 17:14:02,961 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-05-02 17:14:02,963 INFO org.apache.hadoop.mapreduce.Job: Job job_local1897020509_0001 failed with state FAILED due to: NA
2017-05-02 17:14:02,969 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2017-05-02 17:52:39,189 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:52:39,533 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:52:54,843 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:52:55,198 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:52:55,593 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 17:52:55,599 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 17:52:55,634 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 17:52:55,742 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 17:52:55,919 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local49173059_0001
2017-05-02 17:52:56,195 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 17:52:56,196 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local49173059_0001
2017-05-02 17:52:56,198 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 17:52:56,212 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 17:52:56,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 17:52:56,298 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local49173059_0001_m_000000_0
2017-05-02 17:52:56,358 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 17:52:56,367 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Assignment1_1/television.txt:0+716
2017-05-02 17:52:56,466 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 17:52:56,467 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 17:52:56,467 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 17:52:56,467 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 17:52:56,467 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 17:52:56,472 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-05-02 17:52:56,485 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-05-02 17:52:56,486 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 17:52:56,486 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 17:52:56,486 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 17:52:56,486 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 17:52:56,494 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 17:52:56,494 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 26214324(104857296)
2017-05-02 17:52:56,495 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 17:52:56,495 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 17:52:56,495 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 17:52:56,497 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@463bb934
java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:89)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2012)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:794)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 16 more
2017-05-02 17:52:56,503 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 17:52:56,504 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local49173059_0001
java.lang.Exception: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:89)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:790)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 15 more
2017-05-02 17:52:57,197 INFO org.apache.hadoop.mapreduce.Job: Job job_local49173059_0001 running in uber mode : false
2017-05-02 17:52:57,198 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-05-02 17:52:57,200 INFO org.apache.hadoop.mapreduce.Job: Job job_local49173059_0001 failed with state FAILED due to: NA
2017-05-02 17:52:57,215 INFO org.apache.hadoop.mapreduce.Job: Counters: 10
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=540
		Map output materialized bytes=0
		Input split bytes=141
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
	File Input Format Counters 
		Bytes Read=716
2017-05-02 17:58:34,087 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:58:34,405 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:58:49,846 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 17:58:50,165 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 17:58:50,532 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 17:58:50,538 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 17:58:50,565 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 17:58:50,658 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 17:58:50,823 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1681214314_0001
2017-05-02 17:58:51,095 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 17:58:51,097 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1681214314_0001
2017-05-02 17:58:51,100 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 17:58:51,112 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 17:58:51,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 17:58:51,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1681214314_0001_m_000000_0
2017-05-02 17:58:51,259 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 17:58:51,264 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Assignment1_1/television.txt:0+716
2017-05-02 17:58:51,372 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 17:58:51,372 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 17:58:51,372 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 17:58:51,373 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 17:58:51,373 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 17:58:51,376 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-05-02 17:58:51,392 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-05-02 17:58:51,393 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 17:58:51,393 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 17:58:51,394 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 17:58:51,394 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 17:58:51,399 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 17:58:51,399 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 26214324(104857296)
2017-05-02 17:58:51,399 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 17:58:51,400 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 540; bufvoid = 104857600
2017-05-02 17:58:51,400 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 17:58:51,402 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7b96afad
java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:89)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2012)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:794)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 16 more
2017-05-02 17:58:51,406 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 17:58:51,407 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1681214314_0001
java.lang.Exception: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:164)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1265)
	at org.apache.hadoop.util.QuickSort.fix(QuickSort.java:35)
	at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:89)
	at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:63)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1593)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:720)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:790)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at Assignment5_2.CompanyProduct.readFields(CompanyProduct.java:39)
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:158)
	... 15 more
2017-05-02 17:58:52,099 INFO org.apache.hadoop.mapreduce.Job: Job job_local1681214314_0001 running in uber mode : false
2017-05-02 17:58:52,100 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-05-02 17:58:52,102 INFO org.apache.hadoop.mapreduce.Job: Job job_local1681214314_0001 failed with state FAILED due to: NA
2017-05-02 17:58:52,115 INFO org.apache.hadoop.mapreduce.Job: Counters: 10
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=540
		Map output materialized bytes=0
		Input split bytes=141
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
	File Input Format Counters 
		Bytes Read=716
2017-05-02 18:08:30,007 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 18:08:30,323 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 18:08:44,901 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-05-02 18:08:45,196 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-05-02 18:08:45,563 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-05-02 18:08:45,566 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-05-02 18:08:45,602 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-05-02 18:08:45,696 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-05-02 18:08:45,858 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1299553806_0001
2017-05-02 18:08:46,138 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-05-02 18:08:46,140 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1299553806_0001
2017-05-02 18:08:46,143 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-05-02 18:08:46,157 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-05-02 18:08:46,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-05-02 18:08:46,228 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,301 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,307 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/acadgild/workspace/Assignments/Input/Assignment1_1/television.txt:0+716
2017-05-02 18:08:46,398 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-05-02 18:08:46,398 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-05-02 18:08:46,399 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-05-02 18:08:46,399 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-05-02 18:08:46,399 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-05-02 18:08:46,401 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-05-02 18:08:46,425 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-05-02 18:08:46,426 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-05-02 18:08:46,426 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-05-02 18:08:46,426 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 468; bufvoid = 104857600
2017-05-02 18:08:46,426 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
2017-05-02 18:08:46,456 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-05-02 18:08:46,463 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_m_000000_0 is done. And is in the process of committing
2017-05-02 18:08:46,472 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-05-02 18:08:46,473 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_m_000000_0' done.
2017-05-02 18:08:46,473 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,474 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-05-02 18:08:46,482 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-05-02 18:08:46,485 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_r_000000_0
2017-05-02 18:08:46,495 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,498 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28591b2a
2017-05-02 18:08:46,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 18:08:46,543 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1299553806_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 18:08:46,601 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1299553806_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2017-05-02 18:08:46,609 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,676 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-05-02 18:08:46,683 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 18:08:46,685 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 18:08:46,702 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,703 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2017-05-02 18:08:46,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2017-05-02 18:08:46,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2017-05-02 18:08:46,712 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 18:08:46,712 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,712 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2017-05-02 18:08:46,717 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,733 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-05-02 18:08:46,741 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_r_000000_0 is done. And is in the process of committing
2017-05-02 18:08:46,745 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,747 INFO org.apache.hadoop.mapred.Task: Task attempt_local1299553806_0001_r_000000_0 is allowed to commit now
2017-05-02 18:08:46,750 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1299553806_0001_r_000000_0' to file:/home/acadgild/workspace/Assignments/Output/Task5_2/_temporary/0/task_local1299553806_0001_r_000000
2017-05-02 18:08:46,754 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 18:08:46,756 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_r_000000_0' done.
2017-05-02 18:08:46,756 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_r_000000_0
2017-05-02 18:08:46,759 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_r_000001_0
2017-05-02 18:08:46,762 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,762 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6afaf551
2017-05-02 18:08:46,766 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 18:08:46,772 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1299553806_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 18:08:46,773 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1299553806_0001_m_000000_0 decomp: 146 len: 150 to MEMORY
2017-05-02 18:08:46,776 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 146 bytes from map-output for attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,776 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 146, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->146
2017-05-02 18:08:46,780 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 18:08:46,781 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,781 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 18:08:46,788 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,789 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2017-05-02 18:08:46,791 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 146 bytes to disk to satisfy reduce memory limit
2017-05-02 18:08:46,791 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 150 bytes from disk
2017-05-02 18:08:46,791 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 18:08:46,795 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,795 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2017-05-02 18:08:46,799 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,810 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_r_000001_0 is done. And is in the process of committing
2017-05-02 18:08:46,812 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,812 INFO org.apache.hadoop.mapred.Task: Task attempt_local1299553806_0001_r_000001_0 is allowed to commit now
2017-05-02 18:08:46,813 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1299553806_0001_r_000001_0' to file:/home/acadgild/workspace/Assignments/Output/Task5_2/_temporary/0/task_local1299553806_0001_r_000001
2017-05-02 18:08:46,813 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 18:08:46,819 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_r_000001_0' done.
2017-05-02 18:08:46,820 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_r_000001_0
2017-05-02 18:08:46,822 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_r_000002_0
2017-05-02 18:08:46,825 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,825 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f0d58e9
2017-05-02 18:08:46,832 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 18:08:46,842 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1299553806_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 18:08:46,843 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1299553806_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2017-05-02 18:08:46,849 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-05-02 18:08:46,849 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 18:08:46,850 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,850 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 18:08:46,853 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,853 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2017-05-02 18:08:46,853 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2017-05-02 18:08:46,854 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2017-05-02 18:08:46,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 18:08:46,855 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,856 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2017-05-02 18:08:46,859 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,867 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_r_000002_0 is done. And is in the process of committing
2017-05-02 18:08:46,872 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,872 INFO org.apache.hadoop.mapred.Task: Task attempt_local1299553806_0001_r_000002_0 is allowed to commit now
2017-05-02 18:08:46,873 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1299553806_0001_r_000002_0' to file:/home/acadgild/workspace/Assignments/Output/Task5_2/_temporary/0/task_local1299553806_0001_r_000002
2017-05-02 18:08:46,878 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 18:08:46,878 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_r_000002_0' done.
2017-05-02 18:08:46,879 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_r_000002_0
2017-05-02 18:08:46,879 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_r_000003_0
2017-05-02 18:08:46,885 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,886 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@406de1ce
2017-05-02 18:08:46,888 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 18:08:46,891 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1299553806_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 18:08:46,893 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1299553806_0001_m_000000_0 decomp: 118 len: 122 to MEMORY
2017-05-02 18:08:46,893 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 118 bytes from map-output for attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,893 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 118, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->118
2017-05-02 18:08:46,894 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 18:08:46,894 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,894 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 18:08:46,895 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,896 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-05-02 18:08:46,896 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 118 bytes to disk to satisfy reduce memory limit
2017-05-02 18:08:46,896 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 122 bytes from disk
2017-05-02 18:08:46,903 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 18:08:46,903 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,903 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-05-02 18:08:46,904 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,915 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_r_000003_0 is done. And is in the process of committing
2017-05-02 18:08:46,915 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,919 INFO org.apache.hadoop.mapred.Task: Task attempt_local1299553806_0001_r_000003_0 is allowed to commit now
2017-05-02 18:08:46,920 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1299553806_0001_r_000003_0' to file:/home/acadgild/workspace/Assignments/Output/Task5_2/_temporary/0/task_local1299553806_0001_r_000003
2017-05-02 18:08:46,922 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 18:08:46,922 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_r_000003_0' done.
2017-05-02 18:08:46,922 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_r_000003_0
2017-05-02 18:08:46,922 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1299553806_0001_r_000004_0
2017-05-02 18:08:46,926 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-05-02 18:08:46,926 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f6763dc
2017-05-02 18:08:46,926 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=333512704, maxSingleShuffleLimit=83378176, mergeThreshold=220118400, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-05-02 18:08:46,927 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1299553806_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-05-02 18:08:46,931 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1299553806_0001_m_000000_0 decomp: 246 len: 250 to MEMORY
2017-05-02 18:08:46,931 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 246 bytes from map-output for attempt_local1299553806_0001_m_000000_0
2017-05-02 18:08:46,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 246, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->246
2017-05-02 18:08:46,944 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-05-02 18:08:46,944 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,945 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-05-02 18:08:46,945 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,946 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 220 bytes
2017-05-02 18:08:46,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 246 bytes to disk to satisfy reduce memory limit
2017-05-02 18:08:46,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 250 bytes from disk
2017-05-02 18:08:46,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-05-02 18:08:46,947 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-05-02 18:08:46,947 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 220 bytes
2017-05-02 18:08:46,947 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,964 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1299553806_0001_r_000004_0 is done. And is in the process of committing
2017-05-02 18:08:46,965 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-05-02 18:08:46,965 INFO org.apache.hadoop.mapred.Task: Task attempt_local1299553806_0001_r_000004_0 is allowed to commit now
2017-05-02 18:08:46,966 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1299553806_0001_r_000004_0' to file:/home/acadgild/workspace/Assignments/Output/Task5_2/_temporary/0/task_local1299553806_0001_r_000004
2017-05-02 18:08:46,966 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-05-02 18:08:46,966 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1299553806_0001_r_000004_0' done.
2017-05-02 18:08:46,966 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1299553806_0001_r_000004_0
2017-05-02 18:08:46,966 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-05-02 18:08:47,145 INFO org.apache.hadoop.mapreduce.Job: Job job_local1299553806_0001 running in uber mode : false
2017-05-02 18:08:47,146 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-05-02 18:08:47,147 INFO org.apache.hadoop.mapreduce.Job: Job job_local1299553806_0001 completed successfully
2017-05-02 18:08:47,187 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=15450
		FILE: Number of bytes written=1143592
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=468
		Map output materialized bytes=534
		Input split bytes=141
		Combine input records=0
		Combine output records=0
		Reduce input groups=11
		Reduce shuffle bytes=534
		Reduce input records=18
		Reduce output records=11
		Spilled Records=36
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=19
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=812015616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=716
	File Output Format Counters 
		Bytes Written=372
